# -*- coding: utf-8 -*-
"""Part 4: Multi-Modal Model Definition

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t8ZEcaU1EW8aLCJjcsF6ib5AxjN3Ol8h
"""

from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
from transformers import BertModel
from torchvision.models import resnet18
from torchvision.models.video import r3d_18
from sklearn.metrics import classification_report

class MultiModalDataset(Dataset):
    def __init__(self, dataframe):
        self.df = dataframe

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        text_data = text_transform(str(row['text']))
        image_tensor = load_image(row['image_path'])
        video_tensor = load_video(row['video_path'])
        label = torch.tensor(1 if row['label'] == 'real' else 0, dtype=torch.long)
        return text_data['input_ids'].squeeze(0), text_data['attention_mask'].squeeze(0), image_tensor.squeeze(0), video_tensor.squeeze(0), label

class MultiModalFakeNewsModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.fc_text = nn.Linear(768, 128)
        self.resnet = resnet18(weights="IMAGENET1K_V1")
        self.resnet.fc = nn.Identity()
        self.fc_img = nn.Linear(512, 128)
        self.r3d = r3d_18(weights="KINETICS400_V1")
        self.r3d.fc = nn.Identity()
        self.fc_vid = nn.Linear(512, 128)
        self.classifier = nn.Sequential(
            nn.Linear(128 * 3, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, input_ids, attn_mask, image, video):
        text_feat = self.fc_text(self.bert(input_ids, attention_mask=attn_mask).pooler_output)
        image_feat = self.fc_img(self.resnet(image))
        video_feat = self.fc_vid(self.r3d(video))
        combined = torch.cat((text_feat, image_feat, video_feat), dim=1)
        return self.classifier(combined)